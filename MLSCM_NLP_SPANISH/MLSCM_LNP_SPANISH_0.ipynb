{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ed8a1e",
   "metadata": {},
   "source": [
    "## Data for training and testing\n",
    "\n",
    "This notebook takes the data obtained from [SEPLN](http://tass.sepln.org/tass_data/download.php) and create two data sets: training and testing.\n",
    "\n",
    "\n",
    "## Libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3efe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as et \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1479a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1134181",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"A_RawData/general-train-tagged.xml\"\n",
    "xtree = et.parse(file)\n",
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55f29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the colnames of the dataframe\n",
    "df_cols = [ \"tweet\" , \"sentiment\" ]\n",
    "# I will collect every observation from the key tweet\n",
    "rows = []\n",
    "# I will go over each subsection of the key tweet\n",
    "for node in xroot:\n",
    "    \n",
    "    # Collecting the content of the tweet\n",
    "    s_tweet = node.find( \"content\" ).text\n",
    "    \n",
    "    # Collecting the sentiment of the tweet\n",
    "    # It has a subsectio like polarity\n",
    "    # It has value and type\n",
    "    s_pv= node.findall( \"sentiments\" )\n",
    "    \n",
    "    # Empty list\n",
    "    value=[]\n",
    "    # s_pv has two information sources value and type from polarity\n",
    "    # We will get from polarity the value and append observations \n",
    "    # to the value list\n",
    "    for item in s_pv:\n",
    "        # Getting all information in polarity key\n",
    "        test=item.findall( \"polarity\" )\n",
    "        # Getting the values\n",
    "        value.append(test[ 0 ].find( \"value\" ).text)\n",
    "    # Append into row list a dict conformed by the tweet message (s_tweet)\n",
    "    # And the sentiment value\n",
    "    rows.append({ \"tweet\" : s_tweet, \"sentiment\" : value})\n",
    "\n",
    "# Generating the dataframe\n",
    "training = pd.DataFrame( rows, columns = df_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483949cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salgo de #VeoTV , que día más largoooooo...</td>\n",
       "      <td>[NONE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>[NEU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>[P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>[N+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>[P+]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0        Salgo de #VeoTV , que día más largoooooo...    [NONE]\n",
       "1  @PauladeLasHeras No te libraras de ayudar me/n...     [NEU]\n",
       "2                          @marodriguezb Gracias MAR       [P]\n",
       "3  Off pensando en el regalito Sinde, la que se v...      [N+]\n",
       "4  Conozco a alguien q es adicto al drama! Ja ja ...      [P+]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c07340",
   "metadata": {},
   "source": [
    "**Cleaning the data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e28d9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P+      1652\n",
      "NONE    1483\n",
      "N       1335\n",
      "P       1232\n",
      "N+       847\n",
      "NEU      670\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It will take every observation and chekc if it is a list.\n",
    "# If it is a list, we will get the first value and if not\n",
    "# It will return the same value\n",
    "training2 = training.applymap(lambda x: x[0] if isinstance(x, list) else x)\n",
    "# Change datatype of sentiment column to str\n",
    "training2.sentiment = training2.sentiment.astype(str)\n",
    "# Print the counts of unique values of the sentiment list\n",
    "print(training2[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7355e0",
   "metadata": {},
   "source": [
    "Droping the 'NONE' from sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92073407",
   "metadata": {},
   "outputs": [],
   "source": [
    "training3 = training2[training2[\"sentiment\"]!=\"NONE\"].copy().reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785e0287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P+     1652\n",
      "N      1335\n",
      "P      1232\n",
      "N+      847\n",
      "NEU     670\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(training3[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e147169",
   "metadata": {},
   "source": [
    "Recoding the sentiment to have three categories: \n",
    " - '0' Negative\n",
    " - '1' Neutral\n",
    " - '2' Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1bfcf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5736, 2)\n",
      "2    2884\n",
      "0    2182\n",
      "1     670\n",
      "Name: sentiment, dtype: int64\n",
      "                                               tweet  sentiment\n",
      "0  @PauladeLasHeras No te libraras de ayudar me/n...          1\n",
      "1                          @marodriguezb Gracias MAR          2\n",
      "2  Off pensando en el regalito Sinde, la que se v...          0\n",
      "3  Conozco a alguien q es adicto al drama! Ja ja ...          2\n",
      "4  Toca @crackoviadeTV3 . Grabación dl especial N...          2\n"
     ]
    }
   ],
   "source": [
    "# Changing sentiment variable to values\n",
    "training3[\"sentiment\"]=training3[\"sentiment\"].replace(\"P+\", 2)\n",
    "training3[\"sentiment\"]=training3[\"sentiment\"].replace(\"NEU\", 1)\n",
    "training3[\"sentiment\"]=training3[\"sentiment\"].replace(\"N\", 0)\n",
    "training3[\"sentiment\"]=training3[\"sentiment\"].replace(\"N+\", 0)\n",
    "training3[\"sentiment\"]=training3[\"sentiment\"].replace(\"P\", 2)\n",
    "print(training3.shape)\n",
    "print(training3[\"sentiment\"].value_counts())\n",
    "print(training3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb2d94",
   "metadata": {},
   "source": [
    "Saving the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "949da59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training3.to_excel(\"B_OutputData/trainingTASS_data.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c9942",
   "metadata": {},
   "source": [
    "### Testing data\n",
    "\n",
    "I follow the same steps from above. The training sample is also from TASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "942d341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file2=\"../../Data/Downloaded/TASS_data/politics-test-tagged.xml\"\n",
    "# Parsing data\n",
    "file2 = \"A_RawData/politics-test-tagged.xml\"\n",
    "xtree2 = et.parse(file2)\n",
    "xroot2 = xtree2.getroot()\n",
    "\n",
    "# Generating columns for dataframe\n",
    "df_cols = [ \"tweet\" , \"sentiment\" ]\n",
    "rows = []\n",
    "\n",
    "# We will go over each subsection of the key tweet\n",
    "for node in xroot2: \n",
    "    \n",
    "    # Collecting the content of the tweet\n",
    "    s_tweet = node.find( \"content\" ).text\n",
    "    \n",
    "    # Collecting the sentiment of the tweet\n",
    "    # It has a subsectio like polarity\n",
    "    # It has value and type\n",
    "    s_pv= node.findall( \"sentiments\" )\n",
    "    \n",
    "    # Empty list\n",
    "    value=[]\n",
    "    \n",
    "    # s_pv has two information sources value and type from polarity\n",
    "    # We will get from polarity the value and append observations \n",
    "    # to the value list\n",
    "    for item in s_pv:\n",
    "        \n",
    "        # Getting all information in polarity key\n",
    "        test=item.findall( \"polarity\" )\n",
    "        # Getting values\n",
    "        value1=test[ 0 ].find( \"value\" ).text\n",
    "        value.append( value1 )\n",
    "    \n",
    "    # appending values to the list row\n",
    "    rows.append( { \"tweet\" : s_tweet , \"sentiment\" : value } )\n",
    "\n",
    "# Generating the dataframe\n",
    "testing = pd.DataFrame( rows, columns = df_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d960016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEU     941\n",
      "N       698\n",
      "P       639\n",
      "NONE    222\n",
      "Name: sentiment, dtype: int64\n",
      "Dropping those classified as NONE\n",
      "NEU    941\n",
      "N      698\n",
      "P      639\n",
      "Name: sentiment, dtype: int64\n",
      "Recoding categories\n",
      "New data and value counts\n",
      "(2278, 3)\n",
      "1    941\n",
      "0    698\n",
      "2    639\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# It will take every observation and chekc if it is a list.\n",
    "# If it is a list, we will get the first value and if not\n",
    "# It will return the same value\n",
    "testing2 = testing.applymap(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "# Change datatype of sentiment column to str\n",
    "testing2.sentiment = testing2.sentiment.astype(str)\n",
    "\n",
    "# Print the counts of unique values of the sentiment list\n",
    "print(testing2[\"sentiment\"].value_counts())\n",
    "\n",
    "# Drop NONE observations in sentiment column\n",
    "testing3 = testing2[testing2[\"sentiment\"]!=\"NONE\"].copy().reset_index()\n",
    "print('Dropping those classified as NONE')\n",
    "# Check NONE is not the dataframe\n",
    "print(testing3[\"sentiment\"].value_counts())\n",
    "print('Recoding categories')\n",
    "# Changing sentiment variable to values\n",
    "testing3[\"sentiment\"]=testing3[\"sentiment\"].replace(\"P+\", 2)\n",
    "testing3[\"sentiment\"]=testing3[\"sentiment\"].replace(\"NEU\", 1)\n",
    "testing3[\"sentiment\"]=testing3[\"sentiment\"].replace(\"N\", 0)\n",
    "testing3[\"sentiment\"]=testing3[\"sentiment\"].replace(\"N+\", 0)\n",
    "testing3[\"sentiment\"]=testing3[\"sentiment\"].replace(\"P\", 2)\n",
    "print('New data and value counts')\n",
    "print(testing3.shape)\n",
    "print(testing3[\"sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c45dce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data\n",
    "testing3.to_excel(\"B_OutputData/testingTASS_data.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ceb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
